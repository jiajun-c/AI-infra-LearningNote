{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import  defaultdict\n",
    "\n",
    "def build_vocab(corpus):\n",
    "    word_dict = defaultdict(int)\n",
    "    for sentence in corpus:\n",
    "        for word in sentence:\n",
    "            word_dict[word] += 1\n",
    "    sorted_words = sorted(word_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "    word2idx = {word: i+1 for i, (word, _) in enumerate(sorted_words)}\n",
    "    idx2word = {i: word for i, (word, _) in enumerate(sorted_words)}\n",
    "    return word2idx, idx2word\n",
    "\n",
    "def create_contexts_target(corpus, window_size=2):\n",
    "    contexts, targets = [], []\n",
    "    for sentence in corpus:\n",
    "        for i in range(window_size, len(sentence) - window_size):\n",
    "            target = sentence[i]\n",
    "            context = sentence[i-window_size:i] + sentence[i+1:i+window_size+1]\n",
    "            contexts.append(context)\n",
    "            targets.append(target)\n",
    "    return np.array(contexts), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs)  # [batch_size, context_size, embedding_dim]\n",
    "        mean_embeds = torch.mean(embeds, dim=1)  # [batch_size, embedding_dim]\n",
    "        out = self.linear(mean_embeds)  # [batch_size, vocab_size]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 2.5771\n",
      "Epoch 2, Loss: 2.4970\n",
      "Epoch 3, Loss: 2.4175\n",
      "Epoch 4, Loss: 2.3385\n",
      "Epoch 5, Loss: 2.2602\n",
      "Epoch 6, Loss: 2.1827\n",
      "Epoch 7, Loss: 2.1059\n",
      "Epoch 8, Loss: 2.0300\n",
      "Epoch 9, Loss: 1.9549\n",
      "Epoch 10, Loss: 1.8809\n",
      "Epoch 11, Loss: 1.8078\n",
      "Epoch 12, Loss: 1.7359\n",
      "Epoch 13, Loss: 1.6651\n",
      "Epoch 14, Loss: 1.5956\n",
      "Epoch 15, Loss: 1.5274\n",
      "Epoch 16, Loss: 1.4605\n",
      "Epoch 17, Loss: 1.3952\n",
      "Epoch 18, Loss: 1.3314\n",
      "Epoch 19, Loss: 1.2693\n",
      "Epoch 20, Loss: 1.2088\n",
      "Epoch 21, Loss: 1.1501\n",
      "Epoch 22, Loss: 1.0933\n",
      "Epoch 23, Loss: 1.0383\n",
      "Epoch 24, Loss: 0.9852\n",
      "Epoch 25, Loss: 0.9340\n",
      "Epoch 26, Loss: 0.8849\n",
      "Epoch 27, Loss: 0.8378\n",
      "Epoch 28, Loss: 0.7927\n",
      "Epoch 29, Loss: 0.7496\n",
      "Epoch 30, Loss: 0.7085\n",
      "Epoch 31, Loss: 0.6694\n",
      "Epoch 32, Loss: 0.6323\n",
      "Epoch 33, Loss: 0.5972\n",
      "Epoch 34, Loss: 0.5639\n",
      "Epoch 35, Loss: 0.5325\n",
      "Epoch 36, Loss: 0.5029\n",
      "Epoch 37, Loss: 0.4750\n",
      "Epoch 38, Loss: 0.4487\n",
      "Epoch 39, Loss: 0.4241\n",
      "Epoch 40, Loss: 0.4009\n",
      "Epoch 41, Loss: 0.3793\n",
      "Epoch 42, Loss: 0.3590\n",
      "Epoch 43, Loss: 0.3399\n",
      "Epoch 44, Loss: 0.3222\n",
      "Epoch 45, Loss: 0.3055\n",
      "Epoch 46, Loss: 0.2900\n",
      "Epoch 47, Loss: 0.2755\n",
      "Epoch 48, Loss: 0.2619\n",
      "Epoch 49, Loss: 0.2492\n",
      "Epoch 50, Loss: 0.2374\n"
     ]
    }
   ],
   "source": [
    "# 示例语料库\n",
    "corpus = [\n",
    "    [\"the\", \"quick\", \"brown\", \"fox\", \"jumps\"],\n",
    "    [\"over\", \"the\", \"lazy\", \"dog\"]\n",
    "]\n",
    "\n",
    "# 参数设置\n",
    "EMBEDDING_DIM = 100\n",
    "WINDOW_SIZE = 2\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "\n",
    "# 数据预处理\n",
    "word2idx, idx2word = build_vocab(corpus)\n",
    "contexts, targets = create_contexts_target(corpus, WINDOW_SIZE)\n",
    "\n",
    "# 转换为PyTorch张量\n",
    "context_tensor = torch.LongTensor([[word2idx[w] for w in ctx] for ctx in contexts])\n",
    "target_tensor = torch.LongTensor([word2idx[t] for t in targets])\n",
    "\n",
    "# 初始化模型\n",
    "model = CBOW(len(word2idx)+1, EMBEDDING_DIM)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for i in range(0, len(contexts), BATCH_SIZE):\n",
    "        batch_context = context_tensor[i:i+BATCH_SIZE]\n",
    "        batch_target = target_tensor[i:i+BATCH_SIZE]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_context)\n",
    "        loss = criterion(outputs, batch_target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(contexts):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar to 'fox': ['dog', 'quick', 'jumps']\n"
     ]
    }
   ],
   "source": [
    "# 获取词向量矩阵\n",
    "embeddings = model.embeddings.weight.data\n",
    "\n",
    "# 示例：查找相似词\n",
    "def find_similar(word, topn=3):\n",
    "    word_idx = word2idx[word]\n",
    "    word_vec = embeddings[word_idx]\n",
    "    similarities = torch.matmul(embeddings, word_vec) / (\n",
    "        torch.norm(embeddings, dim=1) * torch.norm(word_vec)\n",
    "    )\n",
    "    _, indices = torch.topk(similarities, topn+1)\n",
    "    indices -= 1\n",
    "    return [idx2word[idx.item()] for idx in indices[1:]] # 排除自身\n",
    "\n",
    "print(\"Similar to 'fox':\", find_similar('fox'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
